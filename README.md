\# TelcoVision - Proyecto MLOps de PredicciÃ³n de Churn


![CI Pipeline](https://github.com/MarceloAlejandroSaucedo/telcovision-churn-mlops/workflows/CI%20Pipeline%20-%20TelcoVision%20Churn/badge.svg)

## Proyecto ISTEA | Materia: MinerÃ­a de datos II


\## ğŸ“‹ DescripciÃ³n del Proyecto



Pipeline reproducible de Machine Learning para predecir la rotaciÃ³n de clientes (churn) en la empresa ficticia \*\*TelcoVision\*\*, aplicando buenas prÃ¡cticas de MLOps con versionado de datos y modelos.



\*\*Contexto:\*\* TelcoVision busca reducir la rotaciÃ³n de clientes mediante un modelo predictivo basado en datos de uso de servicios, informaciÃ³n demogrÃ¡fica y mÃ©todos de pago.



\## ğŸ¯ Objetivos



\- Construir un pipeline ML completamente reproducible

\- Aplicar control de versiones con DVC y Git

\- Trackear experimentos con MLflow

\- Implementar CI/CD con GitHub Actions

\- Predecir churn con mÃ©tricas de alta calidad



\## ğŸ› ï¸ TecnologÃ­as Utilizadas



\- \*\*Python 3.11\*\* - Lenguaje principal

\- \*\*DVC\*\* - Versionado de datos y modelos

\- \*\*Git/GitHub\*\* - Control de versiones de cÃ³digo

\- \*\*DagsHub\*\* - Storage remoto y tracking

\- \*\*MLflow\*\* - Tracking de experimentos

\- \*\*scikit-learn\*\* - Machine Learning

\- \*\*Pandas/NumPy\*\* - ManipulaciÃ³n de datos



\## ğŸ“Š Dataset



\- \*\*Nombre:\*\* telco\_churn.csv

\- \*\*Registros:\*\* 10,000 clientes

\- \*\*Variables:\*\* 13 columnas (demogrÃ¡ficas, servicios, churn)

\- \*\*Target:\*\* churn (1 = se da de baja, 0 = permanece)



\### Variables principales:

\- `customer\_id`: Identificador Ãºnico

\- `age`: Edad del cliente

\- `gender`: GÃ©nero (Male/Female)

\- `tenure\_months`: Meses como cliente

\- `monthly\_charges`: Cargos mensuales

\- `total\_charges`: Cargos totales

\- `contract\_type`: Tipo de contrato

\- `churn`: Variable objetivo



\## âš™ï¸ Requisitos Previos



Antes de comenzar, asegÃºrate de tener instalado:



\- Python 3.11+

\- Conda/Anaconda

\- Git

\- Cuenta en \[DagsHub](https://dagshub.com/)



\## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n



\### 1. Clonar el repositorio



git clone https://github.com/MarceloAlejandroSaucedo/telcovision-churn-mlops.git

cd telcovision-churn-mlops



\### 2. Crear entorno virtual con Conda



Crear entorno

conda create -n telcovision-mlops python=3.11 -y



Activar entorno

conda activate telcovision-mlops




\### 3. Instalar dependencias



pip install -r requirements.txt




\### 4. Configurar credenciales de DagsHub



Para descargar los datos versionados, necesitas configurar tu token de DagsHub:



1\. Ve a \[DagsHub Settings â†’ Tokens](https://dagshub.com/user/settings/tokens)

2\. Genera un nuevo token con permisos de lectura

3\. Configura el remote DVC localmente:



dvc remote modify origin --local auth basic

dvc remote modify origin --local user TU\_USUARIO\_DAGSHUB

dvc remote modify origin --local password TU\_TOKEN\_DAGSHUB






\### 5. Descargar datos versionados



dvc pull






\### 6. Ejecutar el pipeline completo



dvc repro






\## ğŸ“ Estructura del Proyecto

telcovision-churn-mlops/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                  # Datos originales (versionado con DVC)
â”‚   â”‚   â””â”€â”€ telco_churn.csv
â”‚   â””â”€â”€ processed/            # Datos procesados (versionado con DVC)
â”‚       â”œâ”€â”€ X_train.csv
â”‚       â”œâ”€â”€ X_test.csv
â”‚       â”œâ”€â”€ y_train.csv
â”‚       â”œâ”€â”€ y_test.csv
â”‚       â””â”€â”€ metadata.json
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_prep.py          # Script de preparaciÃ³n de datos
â”‚   â”œâ”€â”€ train.py              # Script de entrenamiento del modelo
â”‚   â””â”€â”€ evaluate.py           # Script de evaluaciÃ³n avanzada (Etapa 7)
â”œâ”€â”€ models/                   # Modelos entrenados (versionado con DVC)
â”‚   â”œâ”€â”€ model.joblib
â”‚   â””â”€â”€ metrics.json
â”œâ”€â”€ evaluation/               # Visualizaciones avanzadas (Etapa 7 Bonus)
â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â”œâ”€â”€ roc_curve.png
â”‚   â”œâ”€â”€ precision_recall_curve.png
â”‚   â”œâ”€â”€ classification_report.txt
â”‚   â”œâ”€â”€ classification_report.json
â”‚   â””â”€â”€ advanced_metrics.json
â”œâ”€â”€ .dvc/                     # ConfiguraciÃ³n de DVC
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/            # GitHub Actions CI/CD
â”œâ”€â”€ params.yaml               # ParÃ¡metros configurables del pipeline
â”œâ”€â”€ dvc.yaml                  # DefiniciÃ³n del pipeline DVC
â”œâ”€â”€ dvc.lock                  # Estado del pipeline (reproducibilidad)
â”œâ”€â”€ DEPLOYMENT.md             # Estrategia de deployment
â”œâ”€â”€ requirements.txt          # Dependencias Python
â”œâ”€â”€ .gitignore                # Archivos ignorados por Git
â””â”€â”€ README.md                 # Este archivo







\## ğŸ”„ Pipeline de Trabajo

El proyecto implementa un pipeline reproducible con tres etapas principales:

### Etapa 1: PreparaciÃ³n de Datos (`prepare`)

**Script:** `src/data_prep.py`

**Funciones:**
- Carga del dataset raw
- Limpieza de datos (valores nulos, duplicados)
- CodificaciÃ³n de variables categÃ³ricas (LabelEncoder)
- DivisiÃ³n train/test (80/20) estratificada
- Escalado de variables numÃ©ricas (StandardScaler)
- GeneraciÃ³n de datasets procesados

**Entradas:**
- `data/raw/telco_churn.csv`
- `params.yaml`

**Salidas:**
- `data/processed/X_train.csv`
- `data/processed/X_test.csv`
- `data/processed/y_train.csv`
- `data/processed/y_test.csv`
- `data/processed/metadata.json`

### Etapa 2: Entrenamiento del Modelo (`train`)

**Script:** `src/train.py`

**Funciones:**
- Carga de datos procesados
- Entrenamiento de modelo (Logistic Regression)
- CÃ¡lculo de mÃ©tricas (accuracy, precision, recall, F1, ROC-AUC)
- Guardado del modelo entrenado
- Tracking con MLflow (opcional)

**Entradas:**
- `data/processed/X_train.csv`
- `data/processed/X_test.csv`
- `data/processed/y_train.csv`
- `data/processed/y_test.csv`
- `params.yaml`

**Salidas:**
- `models/model.joblib`
- `metrics.json`

### Etapa 3: EvaluaciÃ³n Avanzada (`evaluate`) â­ BONUS

**Script:** `src/evaluate.py`

**Funciones:**
- GeneraciÃ³n de visualizaciones avanzadas
- Matriz de confusiÃ³n
- Curva ROC
- Curva Precision-Recall
- Reportes de clasificaciÃ³n detallados
- MÃ©tricas adicionales

**Entradas:**
- `data/processed/X_test.csv`
- `data/processed/y_test.csv`
- `models/model.joblib`

**Salidas:**
- `evaluation/confusion_matrix.png`
- `evaluation/roc_curve.png`
- `evaluation/precision_recall_curve.png`
- `evaluation/classification_report.txt`
- `evaluation/classification_report.json`
- `evaluation/advanced_metrics.json`


\## ğŸ“ˆ Reproducibilidad



Para reproducir todo el pipeline desde cero:



Ejecutar todas las etapas

dvc repro



Ver el DAG del pipeline

dvc dag



Verificar estado

dvc status



Ver diferencias en parÃ¡metros

dvc params diff






\## ğŸ”§ ConfiguraciÃ³n de ParÃ¡metros



Edita `params.yaml` para modificar hiperparÃ¡metros sin cambiar cÃ³digo:



data\_prep:

test\_size: 0.2

random\_state: 42

target\_column: churn



train:

model\_type: random\_forest

random\_forest:

n\_estimators: 100

max\_depth: 10

min\_samples\_split: 5

min\_samples\_leaf: 2

random\_state: 42






DespuÃ©s de modificar parÃ¡metros, ejecuta:



dvc repro






DVC detectarÃ¡ automÃ¡ticamente los cambios y solo re-ejecutarÃ¡ las etapas necesarias.



### Experimentos Realizados

Se ejecutaron 3 experimentos variando hiperparÃ¡metros del RandomForestClassifier:

| Experimento | n_estimators | max_depth | min_samples_split | Test Accuracy | Test Recall | Test ROC-AUC |
|-------------|--------------|-----------|-------------------|---------------|-------------|--------------|
| **aided-spit (Baseline)** | 100 | 10 | 5 | 66.65% | 35.90% | 71.21% |
| **raked-skis (Alta potencia)** | 200 | 20 | 2 | 66.80% | **41.40%** | 70.64% |
| **milky-dops (Balanceado) ** | 150 | 15 | 10 | **67.20%** | 40.17% | 70.94% |

### Modelo Seleccionado

**Experimento: milky-dops (Balanceado)**

**JustificaciÃ³n:**
- Mejor accuracy general (67.20%)
- Recall competitivo (40.17%), solo 1.2 puntos menos que el mejor
- Mejor precision (56.92%) reduciendo falsas alarmas
- Balance Ã³ptimo entre todas las mÃ©tricas para uso en producciÃ³n

**MÃ©tricas detalladas del mejor modelo:**
- Test Accuracy: 0.6720
- Test Precision: 0.5692
- Test Recall: 0.4017
- Test F1-Score: 0.4710
- Test ROC-AUC: 0.7094

**ComparaciÃ³n completa:** Ver archivo `experimentos_comparacion.txt` o ejecutar `dvc exp show` para detalles completos.

**ReproducciÃ³n de experimentos:**




\## ğŸ§ª ExperimentaciÃ³n



Para ejecutar experimentos con diferentes hiperparÃ¡metros:



1\. Modifica los valores en `params.yaml`

2\. Ejecuta `dvc repro`

3\. Las mÃ©tricas se actualizarÃ¡n automÃ¡ticamente

4\. Compara resultados en DagsHub

5\. Haz commit de los cambios:



git add params.yaml dvc.lock models/metrics.json

git commit -m "exp: test n\_estimators=200"

git push


Ver todos los experimentos
dvc exp show

Aplicar un experimento especÃ­fico
dvc exp apply milky-dops

Ver mÃ©tricas
dvc metrics show


Los experimentos y artefactos estÃ¡n versionados con DVC y disponibles en DagsHub.

\## ğŸ”— Enlaces del Proyecto



\- \*\*Repositorio GitHub:\*\* \[telcovision-churn-mlops](https://github.com/MarceloAlejandroSaucedo/telcovision-churn-mlops)

\- \*\*Proyecto DagsHub:\*\* \[telcovision-churn-mlops](https://dagshub.com/MarceloAlejandroSaucedo/telcovision-churn-mlops)



\## ğŸš¦ CI/CD con GitHub Actions



El proyecto incluye automatizaciÃ³n con GitHub Actions que:



\- Verifica la reproducibilidad del pipeline

\- Ejecuta tests automÃ¡ticos

\- Valida la calidad del cÃ³digo

\- Se ejecuta en cada push o pull request



\## ğŸ› ResoluciÃ³n de Problemas



\### Error: "dvc pull" falla



Verificar configuraciÃ³n de remote

dvc remote list



Reconfigurar credenciales

dvc remote modify origin --local auth basic

dvc remote modify origin --local user TU\_USUARIO

dvc remote modify origin --local password TU\_TOKEN






\### Error: "dvc repro" no detecta cambios



Forzar re-ejecuciÃ³n de una etapa especÃ­fica

dvc repro -f prepare



O de todo el pipeline

dvc repro -f






\### Error: Falta algÃºn archivo



Descargar todos los archivos trackeados

dvc pull



Verificar status

dvc status


## Resultados Finales

### Modelo en ProducciÃ³n

**Algoritmo seleccionado:** Logistic Regression

| MÃ©trica | Valor |
|---------|-------|
| Test Accuracy | 67.45% |
| Test Precision | 56.10% |
| Test Recall | 44.44% |
| Test F1-Score | 48.37% |
| Test ROC-AUC | 70.54% |
| PR-AUC | 54.24% |

### Experimentos Evaluados

Se probaron 3 enfoques diferentes mediante Pull Requests:

| Experimento | Accuracy | F1-Score | DecisiÃ³n |
|-------------|----------|----------|----------|
| Logistic Regression | 67.45% | 48.37% | âœ… Seleccionado |
| RF Tuning | 66.85% | 47.17% | âŒ Descartado |
| Feature Engineering | 66.55% | 45.65% | âŒ Overfitting |

**JustificaciÃ³n:** Logistic Regression demostrÃ³ el mejor balance entre performance y simplicidad, evitando overfitting.

### Visualizaciones

El pipeline genera automÃ¡ticamente:
- Matriz de confusiÃ³n para anÃ¡lisis de errores
- Curva ROC para evaluar discriminaciÃ³n del modelo
- Curva Precision-Recall para datasets desbalanceados
- Reportes de clasificaciÃ³n detallados

**Ver:** Carpeta `evaluation/` despuÃ©s de ejecutar `dvc repro`

## ğŸš€ Deployment

Para informaciÃ³n sobre estrategia de deployment en producciÃ³n, ver [DEPLOYMENT.md](DEPLOYMENT.md)

Incluye:
- Arquitectura propuesta (API REST vs Batch)
- Stack tecnolÃ³gico recomendado
- Estrategia de monitoreo y reentrenamiento
- EstimaciÃ³n de costos



\## ğŸ‘¤ Autor



\*\*Marcelo Alejandro Saucedo\*\*

\*\*Daniel Alejandro Bastidas\*\*

\*\*Rosario Ratto\*\*

\- GitHub: \[@MarceloAlejandroSaucedo](https://github.com/MarceloAlejandroSaucedo)

\- Curso: Laboratorio de MinerÃ­a de Datos II - ISTEA

\- Fecha: Octubre 2025

---

## ğŸš€ CI/CD Status

Este proyecto utiliza GitHub Actions para validar automÃ¡ticamente cada cambio.



